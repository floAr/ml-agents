{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unity ML Agents\n",
    "## Proximal Policy Optimization (PPO)\n",
    "Contains an implementation of PPO as described [here](https://arxiv.org/abs/1707.06347)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from ppo.history import *\n",
    "from ppo.models import *\n",
    "from ppo.trainer import Trainer\n",
    "from unityagents import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### General parameters\n",
    "max_steps = 5e6 # Set maximum number of steps to run environment.\n",
    "run_path = \"ppo_reward5\" # The sub-directory name for model and summary statistics\n",
    "load_model = False # Whether to load a saved model.\n",
    "train_model = True # Whether to train the model.\n",
    "summary_freq = 10000 # Frequency at which to save training statistics.\n",
    "save_freq = 50000 # Frequency at which to save model.\n",
    "env_name = \"deep_drive\" # Name of the training environment file.\n",
    "curriculum_file = \"curricula/deepdrive.json\"\n",
    "\n",
    "### Algorithm-specific parameters for tuning\n",
    "gamma = 0.99 # Reward discount rate.\n",
    "lambd = 0.95 # Lambda parameter for GAE.\n",
    "time_horizon = 2048 # How many steps to collect per agent before adding to buffer.\n",
    "beta = 1e-3 # Strength of entropy regularization\n",
    "num_epoch = 5 # Number of gradient descent steps per batch of experiences.\n",
    "num_layers = 2 # Number of hidden layers between state/observation encoding and value/policy layers.\n",
    "epsilon = 0.2 # Acceptable threshold around ratio of old and new policy probabilities.\n",
    "buffer_size = 2048 # How large the experience buffer should be before gradient descent.\n",
    "learning_rate = 3e-4 # Model learning rate.\n",
    "hidden_units = 64 # Number of units in hidden layer.\n",
    "batch_size = 64 # How many experiences per gradient descent update step.\n",
    "normalize = False\n",
    "\n",
    "### Logging dictionary for hyperparameters\n",
    "hyperparameter_dict = {'max_steps':max_steps, 'run_path':run_path, 'env_name':env_name,\n",
    "    'curriculum_file':curriculum_file, 'gamma':gamma, 'lambd':lambd, 'time_horizon':time_horizon,\n",
    "    'beta':beta, 'num_epoch':num_epoch, 'epsilon':epsilon, 'buffe_size':buffer_size,\n",
    "    'leaning_rate':learning_rate, 'hidden_units':hidden_units, 'batch_size':batch_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of brains: 1\n",
      "        Reset Parameters :\n",
      "\t\tother_cars -> 15.0\n",
      "\t\trestart_on_crash -> 1.0\n",
      "Unity brain name: RedAgentBrain\n",
      "        Number of observations (per agent): 0\n",
      "        State space type: continuous\n",
      "        State space size (per agent): 15\n",
      "        Action space type: continuous\n",
      "        Action space size (per agent): 2\n",
      "        Memory space size (per agent): 0\n",
      "        Action descriptions: Acceleration, ChangeLane\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name, curriculum=curriculum_file)\n",
    "print(str(env))\n",
    "brain_name = env.external_brain_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Agent(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10000. Mean Reward: -1.0680666666666536. Std of Reward: 0.3170890971880765.\n",
      "Step: 20000. Mean Reward: 0.8817833333333412. Std of Reward: 4.28203713802074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 1 : \tother_cars -> 0, restart_on_crash -> 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 30000. Mean Reward: 4.779166666666669. Std of Reward: 5.611004649694106.\n",
      "Step: 40000. Mean Reward: 10.377616666666668. Std of Reward: 0.00993049456080604.\n",
      "Step: 50000. Mean Reward: 8.891542857142857. Std of Reward: 3.6402145379701163.\n",
      "Saved Model\n",
      "Step: 60000. Mean Reward: 8.45935714285714. Std of Reward: 3.6199922998565093.\n",
      "Step: 70000. Mean Reward: 10.044283333333334. Std of Reward: 0.46553345177572647.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 2 : \tother_cars -> 1, restart_on_crash -> 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 80000. Mean Reward: 7.304342857142858. Std of Reward: 4.864007473812733.\n",
      "Step: 90000. Mean Reward: 7.247985714285717. Std of Reward: 4.94869938163513.\n",
      "Step: 100000. Mean Reward: 10.377566666666668. Std of Reward: 0.009316949906247932.\n",
      "Saved Model\n",
      "Step: 110000. Mean Reward: 4.110100000000001. Std of Reward: 5.43644782818445.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 3 : \tother_cars -> 1, restart_on_crash -> 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 120000. Mean Reward: 5.667985714285715. Std of Reward: 5.4417869327294035.\n",
      "Step: 130000. Mean Reward: 10.377550000000001. Std of Reward: 0.009280041307378225.\n",
      "Step: 140000. Mean Reward: 8.605814285714287. Std of Reward: 3.550665610207501.\n",
      "Step: 150000. Mean Reward: 6.030857142857134. Std of Reward: 7.330899991105605.\n",
      "Saved Model\n",
      "Step: 160000. Mean Reward: 10.372300000000001. Std of Reward: 0.01609295912296134.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 4 : \tother_cars -> 5, restart_on_crash -> 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 170000. Mean Reward: 5.461114285714286. Std of Reward: 5.410375385558109.\n",
      "Step: 180000. Mean Reward: 0.8543428571428588. Std of Reward: 3.8983617415734098.\n",
      "Step: 190000. Mean Reward: -1.0037666666666654. Std of Reward: 0.10772875918507421.\n",
      "Step: 200000. Mean Reward: -0.8426285714285703. Std of Reward: 0.33983049436146684.\n",
      "Saved Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 5 : \tother_cars -> 5, restart_on_crash -> 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 210000. Mean Reward: 2.379000000000002. Std of Reward: 5.066235027259254.\n",
      "Step: 220000. Mean Reward: 10.3857. Std of Reward: 0.012299999999998867.\n",
      "Step: 230000. Mean Reward: -5238.365649999797. Std of Reward: 5236.595449999797.\n",
      "Step: 240000. Mean Reward: -684.3231333333193. Std of Reward: 923.4487023126185.\n",
      "Step: 250000. Mean Reward: 8.21470000000002. Std of Reward: 1.4202586172947511.\n",
      "Saved Model\n",
      "Step: 260000. Mean Reward: -3.3678799999999853. Std of Reward: 16.531689040675772.\n",
      "Step: 270000. Mean Reward: -3523.546850000475. Std of Reward: 3533.920550000475.\n",
      "Step: 280000. Mean Reward: 9.230400000000017. Std of Reward: 0.0.\n",
      "Step: 290000. Mean Reward: -4384.761250000395. Std of Reward: 4364.988950000395.\n",
      "Step: 300000. Mean Reward: -8754.787500000786. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 310000. Mean Reward: -12.781449999999968. Std of Reward: 21.992449999999987.\n",
      "Step: 320000. Mean Reward: -2669.589250000306. Std of Reward: 2679.8175500003063.\n",
      "Step: 330000. Mean Reward: -164.1781000000224. Std of Reward: 0.0.\n",
      "Step: 350000. Mean Reward: -227.49990000003342. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 360000. Mean Reward: -227.49990000003328. Std of Reward: 0.0.\n",
      "Step: 380000. Mean Reward: -231.49990000003396. Std of Reward: 0.0.\n",
      "Step: 390000. Mean Reward: -228.49990000003345. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 410000. Mean Reward: -227.49990000003325. Std of Reward: 0.0.\n",
      "Step: 420000. Mean Reward: -230.49990000003376. Std of Reward: 0.0.\n",
      "Step: 440000. Mean Reward: -57.52116666667728. Std of Reward: 88.03689905934252.\n",
      "Step: 450000. Mean Reward: -401.441449999982. Std of Reward: 674.3949557209555.\n",
      "Saved Model\n",
      "Step: 460000. Mean Reward: -1472.138199999925. Std of Reward: 0.0.\n",
      "Step: 470000. Mean Reward: -138.23168000000223. Std of Reward: 124.12271509106588.\n",
      "Step: 480000. Mean Reward: -5.39744285714285. Std of Reward: 17.55627670988007.\n",
      "Step: 490000. Mean Reward: -51.42300000000014. Std of Reward: 45.42533791442849.\n",
      "Step: 500000. Mean Reward: -2627.616950000293. Std of Reward: 2593.827450000293.\n",
      "Saved Model\n",
      "Step: 510000. Mean Reward: -2674.200100000307. Std of Reward: 2684.425800000307.\n",
      "Step: 520000. Mean Reward: 6.21430000000002. Std of Reward: 5.64702549017327.\n",
      "Step: 530000. Mean Reward: 6.794533333333342. Std of Reward: 4.938672872566299.\n",
      "Step: 540000. Mean Reward: -4740.227850000239. Std of Reward: 4494.280850000239.\n",
      "Step: 550000. Mean Reward: -138.37280000000055. Std of Reward: 7.587899999999948.\n",
      "Saved Model\n",
      "Step: 560000. Mean Reward: -132.53700000000012. Std of Reward: 142.75870000000012.\n",
      "Step: 570000. Mean Reward: -3192.806566666745. Std of Reward: 4522.593468450052.\n",
      "Step: 580000. Mean Reward: 6.717900000000019. Std of Reward: 3.4896000000000003.\n",
      "Step: 590000. Mean Reward: -2703.267700000306. Std of Reward: 2630.4378000003057.\n",
      "Step: 600000. Mean Reward: 2.6501000000000285. Std of Reward: 2.176148060220165.\n",
      "Saved Model\n",
      "Step: 610000. Mean Reward: 8.217799999999992. Std of Reward: 1.9890000000000274.\n",
      "Step: 620000. Mean Reward: -1801.094200000133. Std of Reward: 1793.3211000001331.\n",
      "Step: 630000. Mean Reward: 4.967833333333331. Std of Reward: 4.7768462680819885.\n",
      "Step: 650000. Mean Reward: -2542.552774999982. Std of Reward: 4300.95316796145.\n",
      "Saved Model\n",
      "Step: 660000. Mean Reward: -367.60159999999206. Std of Reward: 738.6085720612107.\n",
      "Step: 670000. Mean Reward: -99.87280000000032. Std of Reward: 30.927300000000407.\n",
      "Step: 680000. Mean Reward: -14.841825000000028. Std of Reward: 28.395653990740836.\n",
      "Step: 690000. Mean Reward: 7.108475000000014. Std of Reward: 4.301098436082932.\n",
      "Step: 700000. Mean Reward: -4.2860999999999985. Std of Reward: 20.749908233210736.\n",
      "Saved Model\n",
      "Step: 710000. Mean Reward: -8741.781300000795. Std of Reward: 0.0.\n",
      "Step: 720000. Mean Reward: -12126.129899998448. Std of Reward: 0.0.\n",
      "Step: 730000. Mean Reward: -25.788400000000024. Std of Reward: 23.001237275126474.\n",
      "Step: 740000. Mean Reward: 1.5128500000000127. Std of Reward: 1.6999500000000083.\n",
      "Step: 750000. Mean Reward: -13830.209899997268. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 760000. Mean Reward: -71.78040000000009. Std of Reward: 0.0.\n",
      "Step: 770000. Mean Reward: -4364.296500000403. Std of Reward: 4361.522900000403.\n",
      "Step: 780000. Mean Reward: -673.0153333333195. Std of Reward: 911.0960582506473.\n",
      "Step: 790000. Mean Reward: -51.94289999999976. Std of Reward: 0.0.\n",
      "Step: 800000. Mean Reward: -7024.646900000944. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 810000. Mean Reward: -2478.806566667018. Std of Reward: 3512.7041943877566.\n",
      "Step: 820000. Mean Reward: -37.62105000000009. Std of Reward: 48.015050000000095.\n",
      "Step: 830000. Mean Reward: -4996.79014999996. Std of Reward: 5007.01744999996.\n",
      "Step: 840000. Mean Reward: -2698.7985000003064. Std of Reward: 2657.0000000003065.\n",
      "Step: 850000. Mean Reward: -839.958499999982. Std of Reward: 775.1575999999818.\n",
      "Saved Model\n",
      "Step: 860000. Mean Reward: -3.594199999999901. Std of Reward: 12.980541164630372.\n",
      "Step: 870000. Mean Reward: 0.8576250000000717. Std of Reward: 11.106903812803685.\n",
      "Step: 880000. Mean Reward: -1710.4682500001188. Std of Reward: 1714.6701500001188.\n",
      "Step: 890000. Mean Reward: -8.575780000000119. Std of Reward: 32.7887429010875.\n",
      "Step: 900000. Mean Reward: -10.192216666666752. Std of Reward: 25.47514079931117.\n",
      "Saved Model\n",
      "Step: 910000. Mean Reward: -553.0814666666548. Std of Reward: 777.6140267372174.\n",
      "Step: 920000. Mean Reward: -27.10507500000036. Std of Reward: 58.870453891378745.\n",
      "Step: 930000. Mean Reward: -37.89105000000018. Std of Reward: 62.017352230747115.\n",
      "Step: 940000. Mean Reward: 3.202000000000013. Std of Reward: 9.910833711651113.\n",
      "Step: 950000. Mean Reward: -811.4845999999827. Std of Reward: 821.7109999999827.\n",
      "Saved Model\n",
      "Step: 960000. Mean Reward: -592.9019999999867. Std of Reward: 786.6209825151057.\n",
      "Step: 970000. Mean Reward: -54.88020000000003. Std of Reward: 36.9452000000003.\n",
      "Step: 980000. Mean Reward: -342.2108999999918. Std of Reward: 699.8995271727656.\n",
      "Step: 990000. Mean Reward: -92.57678000000085. Std of Reward: 118.68440206159151.\n",
      "Step: 1000000. Mean Reward: -19.63400000000001. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 1010000. Mean Reward: -6094.021399999258. Std of Reward: 5913.194399999257.\n",
      "Step: 1020000. Mean Reward: -503.1381249999888. Std of Reward: 848.3630918562105.\n",
      "Step: 1030000. Mean Reward: -85.46840000000151. Std of Reward: 45.49131908712673.\n",
      "Step: 1040000. Mean Reward: -13.55852500000005. Std of Reward: 35.6200166089501.\n",
      "Step: 1050000. Mean Reward: -373.6473999999919. Std of Reward: 642.7594628027247.\n",
      "Saved Model\n",
      "Step: 1060000. Mean Reward: -22.805450000000196. Std of Reward: 33.005650000000216.\n",
      "Step: 1070000. Mean Reward: -1568.9943500000802. Std of Reward: 1458.1026500000798.\n",
      "Step: 1080000. Mean Reward: -11920.08989999858. Std of Reward: 0.0.\n",
      "Step: 1090000. Mean Reward: -29.12696666666673. Std of Reward: 28.009753688948408.\n",
      "Step: 1100000. Mean Reward: -17.779200000000095. Std of Reward: 35.128364854174606.\n",
      "Saved Model\n",
      "Step: 1110000. Mean Reward: -50.11737142857222. Std of Reward: 79.33689569312693.\n",
      "Step: 1120000. Mean Reward: -132.30058333333113. Std of Reward: 243.22998419575853.\n",
      "Step: 1130000. Mean Reward: -875.7878499999816. Std of Reward: 886.1483499999816.\n",
      "Step: 1140000. Mean Reward: -51.72656666667006. Std of Reward: 35.82185883082743.\n",
      "Step: 1150000. Mean Reward: -28.13550000000015. Std of Reward: 22.88254576280077.\n",
      "Saved Model\n",
      "Step: 1160000. Mean Reward: -7.976420000000033. Std of Reward: 19.67524528562738.\n",
      "Step: 1170000. Mean Reward: -349.5760199999926. Std of Reward: 689.3743647900413.\n",
      "Step: 1180000. Mean Reward: -83.06302000000122. Std of Reward: 65.90073301721011.\n",
      "Step: 1190000. Mean Reward: -50.28882500000035. Std of Reward: 88.55474761450938.\n",
      "Step: 1200000. Mean Reward: -113.25604285714283. Std of Reward: 144.26318384783306.\n",
      "Saved Model\n",
      "Step: 1210000. Mean Reward: -172.63040000000058. Std of Reward: 0.0.\n",
      "Step: 1220000. Mean Reward: -5997.382699999268. Std of Reward: 5982.586699999268.\n",
      "Step: 1230000. Mean Reward: -18.895875000000043. Std of Reward: 44.70510904093495.\n",
      "Step: 1240000. Mean Reward: -39.133866666666755. Std of Reward: 36.97401734320415.\n",
      "Step: 1250000. Mean Reward: -77.1699799999992. Std of Reward: 169.28768934238857.\n",
      "Saved Model\n",
      "Step: 1260000. Mean Reward: -116.82814285714245. Std of Reward: 137.6099275435957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1270000. Mean Reward: -20.63430000000057. Std of Reward: 43.55460811108363.\n",
      "Step: 1280000. Mean Reward: -9.97274285714297. Std of Reward: 30.201885055305535.\n",
      "Step: 1290000. Mean Reward: -480.55063999999237. Std of Reward: 712.0748008013397.\n",
      "Step: 1300000. Mean Reward: -85.46929999999976. Std of Reward: 133.8999346990876.\n",
      "Saved Model\n",
      "Step: 1310000. Mean Reward: -330.1008249999933. Std of Reward: 554.3976120113151.\n",
      "Step: 1320000. Mean Reward: -93.52260000000048. Std of Reward: 78.40934787693851.\n",
      "Step: 1330000. Mean Reward: -102.88385000000311. Std of Reward: 113.08245000000313.\n",
      "Step: 1340000. Mean Reward: -5.554766666666666. Std of Reward: 15.038036890129296.\n",
      "Step: 1350000. Mean Reward: -480.21906666665865. Std of Reward: 560.8106452937824.\n",
      "Saved Model\n",
      "Step: 1360000. Mean Reward: -39.1384333333336. Std of Reward: 34.97268708123865.\n",
      "Step: 1370000. Mean Reward: -89.37612000000038. Std of Reward: 83.46069894151178.\n",
      "Step: 1380000. Mean Reward: -35.35072500000144. Std of Reward: 43.06906230325952.\n",
      "Step: 1400000. Mean Reward: -6871.4227999986715. Std of Reward: 6843.617099998671.\n",
      "Saved Model\n",
      "Step: 1410000. Mean Reward: -36.14345000000022. Std of Reward: 73.83169777993433.\n",
      "Step: 1420000. Mean Reward: 5.363900000000011. Std of Reward: 0.0.\n",
      "Step: 1430000. Mean Reward: -6062.002499999247. Std of Reward: 5975.2011999992465.\n",
      "Step: 1440000. Mean Reward: -38.894550000001466. Std of Reward: 44.22089044538362.\n",
      "Step: 1450000. Mean Reward: -8.804766666666724. Std of Reward: 26.165348710630532.\n",
      "Saved Model\n",
      "Step: 1460000. Mean Reward: 6.690599999999991. Std of Reward: 4.103113258246719.\n",
      "Step: 1470000. Mean Reward: -101.82809999999986. Std of Reward: 117.43581337423608.\n",
      "Step: 1480000. Mean Reward: -9.303100000000045. Std of Reward: 39.220744874024795.\n",
      "Step: 1490000. Mean Reward: -38.713516666667. Std of Reward: 56.95059080701538.\n",
      "Step: 1500000. Mean Reward: -37.116914285714486. Std of Reward: 35.186244080989304.\n",
      "Saved Model\n",
      "Step: 1510000. Mean Reward: -20.469850000000154. Std of Reward: 39.38381028945583.\n",
      "Step: 1520000. Mean Reward: -7.142150000000075. Std of Reward: 16.28399134597643.\n",
      "Step: 1530000. Mean Reward: -20.351600000000733. Std of Reward: 38.22683115777578.\n",
      "Step: 1540000. Mean Reward: -3.6377250000000716. Std of Reward: 20.79994352412715.\n",
      "Step: 1550000. Mean Reward: -3441.245750000463. Std of Reward: 3450.4428500004633.\n",
      "Saved Model\n",
      "Step: 1560000. Mean Reward: -132.3941499999977. Std of Reward: 231.86172930995033.\n",
      "Step: 1570000. Mean Reward: -261.1340999999967. Std of Reward: 394.0607917989686.\n",
      "Step: 1580000. Mean Reward: -46.29645000000023. Std of Reward: 80.15459826129265.\n",
      "Step: 1590000. Mean Reward: -61.15915000000023. Std of Reward: 52.45018646871066.\n",
      "Step: 1600000. Mean Reward: -42.79733333333346. Std of Reward: 72.20761808511335.\n",
      "Saved Model\n",
      "Step: 1610000. Mean Reward: -104.53705714285604. Std of Reward: 200.3406167040272.\n",
      "Step: 1620000. Mean Reward: -3.6820857142856958. Std of Reward: 18.445932036121775.\n",
      "Step: 1630000. Mean Reward: 10.381050000000002. Std of Reward: 0.0075499999999992795.\n",
      "Step: 1640000. Mean Reward: -10367.831799999667. Std of Reward: 0.0.\n",
      "Step: 1650000. Mean Reward: -12089.379899998472. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 1660000. Mean Reward: -19.7812. Std of Reward: 0.0.\n",
      "Step: 1670000. Mean Reward: -4323.253450000428. Std of Reward: 4333.475150000428.\n",
      "Step: 1680000. Mean Reward: -8695.121500000827. Std of Reward: 0.0.\n",
      "Step: 1700000. Mean Reward: -6020.90919999925. Std of Reward: 6031.130699999249.\n",
      "Saved Model\n",
      "Step: 1710000. Mean Reward: -26.140250000000044. Std of Reward: 45.96397957561451.\n",
      "Step: 1720000. Mean Reward: -2502.368850000269. Std of Reward: 2424.734050000269.\n",
      "Step: 1730000. Mean Reward: -49.85087500000027. Std of Reward: 57.421647326961256.\n",
      "Step: 1740000. Mean Reward: -82.63445000000033. Std of Reward: 95.43780284584612.\n",
      "Step: 1750000. Mean Reward: -14.224500000000006. Std of Reward: 32.79947530458379.\n",
      "Saved Model\n",
      "Step: 1760000. Mean Reward: -2641.7029000003004. Std of Reward: 2651.9240000003006.\n",
      "Step: 1770000. Mean Reward: -8650.750900000858. Std of Reward: 0.0.\n",
      "Step: 1780000. Mean Reward: -24.788633333333294. Std of Reward: 21.213156642255967.\n",
      "Step: 1790000. Mean Reward: 3.138000000000009. Std of Reward: 5.132370182154304.\n",
      "Step: 1800000. Mean Reward: -12075.187399998484. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 1810000. Mean Reward: -0.4551999999999836. Std of Reward: 15.090578605430169.\n",
      "Step: 1820000. Mean Reward: -56.57762000000046. Std of Reward: 61.586683916035554.\n",
      "Step: 1830000. Mean Reward: -140.21915000000078. Std of Reward: 86.89733223154245.\n",
      "Step: 1840000. Mean Reward: -138.6283000000009. Std of Reward: 0.0.\n",
      "Step: 1850000. Mean Reward: -5716.467999999457. Std of Reward: 5726.673499999457.\n",
      "Saved Model\n",
      "Step: 1860000. Mean Reward: -21.14375000000007. Std of Reward: 47.3159475655673.\n",
      "Step: 1870000. Mean Reward: 10.372. Std of Reward: 0.0.\n",
      "Step: 1880000. Mean Reward: -6051.3270999992765. Std of Reward: 5933.534699999276.\n",
      "Step: 1890000. Mean Reward: -60.636775000001. Std of Reward: 97.86787812953347.\n",
      "Step: 1900000. Mean Reward: -11.45539999999999. Std of Reward: 21.511932804531238.\n",
      "Saved Model\n",
      "Step: 1910000. Mean Reward: -4.770299999999988. Std of Reward: 14.849623145117178.\n",
      "Step: 1920000. Mean Reward: -885.9852750000633. Std of Reward: 1534.6863613699197.\n",
      "Step: 1930000. Mean Reward: 10.21110000000002. Std of Reward: 0.0.\n",
      "Step: 1940000. Mean Reward: -4347.417100000421. Std of Reward: 4324.633800000421.\n",
      "Step: 1950000. Mean Reward: 2.3609500000000003. Std of Reward: 8.106671453037947.\n",
      "Saved Model\n",
      "Step: 1960000. Mean Reward: -117.96616666666569. Std of Reward: 183.96971234079444.\n",
      "Step: 1970000. Mean Reward: -611.8842333333204. Std of Reward: 877.7906341500973.\n",
      "Step: 1980000. Mean Reward: -708.3130333333202. Std of Reward: 828.6730580849195.\n",
      "Step: 1990000. Mean Reward: 9.713200000000018. Std of Reward: 0.49350000000000005.\n",
      "Step: 2000000. Mean Reward: -2617.6535000002955. Std of Reward: 2622.8726000002957.\n",
      "Saved Model\n",
      "Step: 2010000. Mean Reward: -14.644650000000041. Std of Reward: 32.65664808783208.\n",
      "Step: 2020000. Mean Reward: -61.9584666666677. Std of Reward: 36.53860675909291.\n",
      "Step: 2030000. Mean Reward: -4383.803350000426. Std of Reward: 4275.010850000426.\n",
      "Step: 2040000. Mean Reward: -1.1367500000000037. Std of Reward: 7.380304870566008.\n",
      "Step: 2050000. Mean Reward: 9.875466666666668. Std of Reward: 1.1191016287878215.\n",
      "Saved Model\n",
      "Step: 2060000. Mean Reward: -641.2200333333203. Std of Reward: 870.272186440865.\n",
      "Step: 2070000. Mean Reward: 2.362150000000001. Std of Reward: 8.696213796388655.\n",
      "Step: 2080000. Mean Reward: 1.8754833333333396. Std of Reward: 15.625969614972867.\n",
      "Step: 2090000. Mean Reward: -623.5210333333204. Std of Reward: 875.2224365622928.\n",
      "Step: 2100000. Mean Reward: -622.9295333333205. Std of Reward: 865.8612924471819.\n",
      "Saved Model\n",
      "Step: 2110000. Mean Reward: -19.790800000000015. Std of Reward: 13.36932414173083.\n",
      "Step: 2120000. Mean Reward: -916.9791999999808. Std of Reward: 926.1979999999809.\n",
      "Step: 2130000. Mean Reward: -257.8920749999959. Std of Reward: 377.59765245143063.\n",
      "Step: 2140000. Mean Reward: -58.718200000000195. Std of Reward: 55.97427061860686.\n",
      "Step: 2150000. Mean Reward: -51.77784000000027. Std of Reward: 77.7495412092088.\n",
      "Saved Model\n",
      "Step: 2160000. Mean Reward: -0.11520000000002673. Std of Reward: 20.499545758591193.\n",
      "Step: 2180000. Mean Reward: -6831.964899998723. Std of Reward: 6709.154999998723.\n",
      "Step: 2190000. Mean Reward: -7.642399999999933. Std of Reward: 13.458584098076557.\n",
      "Step: 2200000. Mean Reward: 10.198900000000018. Std of Reward: 0.0030408332191464078.\n",
      "Saved Model\n",
      "Step: 2210000. Mean Reward: -60.978160000000344. Std of Reward: 96.91857642996264.\n",
      "Step: 2220000. Mean Reward: -74.17492000000068. Std of Reward: 112.88583727935884.\n",
      "Step: 2230000. Mean Reward: -10.076666666668196. Std of Reward: 28.91107437578803.\n",
      "Step: 2240000. Mean Reward: -5.354125000000003. Std of Reward: 13.938416353799878.\n",
      "Step: 2250000. Mean Reward: -72.57750000000028. Std of Reward: 90.10788644497276.\n",
      "Saved Model\n",
      "Step: 2260000. Mean Reward: 3.8654333333333786. Std of Reward: 8.328600264283399.\n",
      "Step: 2270000. Mean Reward: -36.9879000000001. Std of Reward: 36.82370000000011.\n",
      "Step: 2280000. Mean Reward: -2312.9699000003143. Std of Reward: 3278.386209643478.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2290000. Mean Reward: -35.45973333333335. Std of Reward: 43.39894230941075.\n",
      "Step: 2300000. Mean Reward: -88.96583999999932. Std of Reward: 157.63849732547556.\n",
      "Saved Model\n",
      "Step: 2310000. Mean Reward: -3498.0703000004623. Std of Reward: 3428.435700000462.\n",
      "Step: 2320000. Mean Reward: -7.287899999999952. Std of Reward: 17.498099999999972.\n",
      "Step: 2330000. Mean Reward: -2645.8054000002967. Std of Reward: 2613.0185000002966.\n",
      "Step: 2340000. Mean Reward: -8631.922900000873. Std of Reward: 0.0.\n",
      "Step: 2350000. Mean Reward: 10.210266666666685. Std of Reward: 0.004973485252371506.\n",
      "Saved Model\n",
      "Step: 2360000. Mean Reward: -91.56791999999888. Std of Reward: 183.77294009527296.\n",
      "Step: 2370000. Mean Reward: -148.55996666666468. Std of Reward: 291.1633483376679.\n",
      "Step: 2380000. Mean Reward: -277.80199999999803. Std of Reward: 111.04049999999724.\n",
      "Step: 2390000. Mean Reward: -138.14565000000078. Std of Reward: 126.53765306234979.\n",
      "Step: 2400000. Mean Reward: -70.89060000000025. Std of Reward: 78.7301993806382.\n",
      "Saved Model\n",
      "Step: 2410000. Mean Reward: -60.63722500000026. Std of Reward: 74.45599022430581.\n",
      "Step: 2420000. Mean Reward: -198.12694999996071. Std of Reward: 157.32364999996062.\n",
      "Step: 2430000. Mean Reward: -64.14404999999968. Std of Reward: 122.86844019443062.\n",
      "Step: 2440000. Mean Reward: -157.63691999999895. Std of Reward: 147.21295898439513.\n",
      "Step: 2450000. Mean Reward: -38.086333333334245. Std of Reward: 46.678544719878374.\n",
      "Saved Model\n",
      "Step: 2460000. Mean Reward: -448.60147499999107. Std of Reward: 768.051331230447.\n",
      "Step: 2470000. Mean Reward: -36.468750000001315. Std of Reward: 46.048159032991094.\n",
      "Step: 2480000. Mean Reward: -83.09745000000112. Std of Reward: 87.31906264148486.\n",
      "Step: 2490000. Mean Reward: -2638.212100000295. Std of Reward: 2550.55900000029.\n",
      "Step: 2500000. Mean Reward: -21.80425000000005. Std of Reward: 31.00545000000007.\n",
      "Saved Model\n",
      "Step: 2510000. Mean Reward: -116.94609999999959. Std of Reward: 145.3636003361673.\n",
      "Step: 2520000. Mean Reward: -30.6479333333349. Std of Reward: 29.169627634505144.\n",
      "Step: 2530000. Mean Reward: -40.43812000000015. Std of Reward: 47.18036135628481.\n",
      "Step: 2540000. Mean Reward: -45.95680000000114. Std of Reward: 70.02044064037534.\n",
      "Step: 2550000. Mean Reward: -8506.874300000967. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 2560000. Mean Reward: -4.135233333333331. Std of Reward: 20.274354192153442.\n",
      "Step: 2570000. Mean Reward: -90.37831999999872. Std of Reward: 195.17419727502045.\n",
      "Step: 2580000. Mean Reward: -44.77428000000012. Std of Reward: 81.53682497623792.\n",
      "Step: 2590000. Mean Reward: -261.38434999998486. Std of Reward: 208.4273499999796.\n",
      "Step: 2600000. Mean Reward: -26.907900000000055. Std of Reward: 51.7682572780529.\n",
      "Saved Model\n",
      "Step: 2610000. Mean Reward: -8534.057000000948. Std of Reward: 0.0.\n",
      "Step: 2620000. Mean Reward: -35.135600000000274. Std of Reward: 62.70424969526962.\n",
      "Step: 2630000. Mean Reward: -11.175780000000055. Std of Reward: 37.95251040900468.\n",
      "Step: 2640000. Mean Reward: -40.162150000000175. Std of Reward: 55.35484136636886.\n",
      "Step: 2650000. Mean Reward: -119.30573333333336. Std of Reward: 135.240473015781.\n",
      "Saved Model\n",
      "Step: 2660000. Mean Reward: -47.86163333333355. Std of Reward: 55.67747875313315.\n",
      "Step: 2670000. Mean Reward: -10194.944499999785. Std of Reward: 0.0.\n",
      "Step: 2680000. Mean Reward: -20.13850000000006. Std of Reward: 42.90278473083081.\n",
      "Step: 2690000. Mean Reward: 8.225880000000005. Std of Reward: 4.197251983095608.\n",
      "Step: 2700000. Mean Reward: -120.12252000000069. Std of Reward: 117.59382979213348.\n",
      "Saved Model\n",
      "Step: 2710000. Mean Reward: -71.30310000000041. Std of Reward: 61.512400000000376.\n",
      "Step: 2720000. Mean Reward: -198.21285000000807. Std of Reward: 89.40065000000777.\n",
      "Step: 2730000. Mean Reward: -4.641825000000782. Std of Reward: 17.77153384606748.\n",
      "Step: 2740000. Mean Reward: -62.255560000000955. Std of Reward: 74.57193256577457.\n",
      "Step: 2750000. Mean Reward: -35.485475000001365. Std of Reward: 74.80265056541937.\n",
      "Saved Model\n",
      "Step: 2760000. Mean Reward: -525.5630333333241. Std of Reward: 594.6347629765737.\n",
      "Step: 2770000. Mean Reward: -35.806550000000115. Std of Reward: 45.999350000000135.\n",
      "Step: 2780000. Mean Reward: -49.614166666666904. Std of Reward: 87.48259756129953.\n",
      "Step: 2790000. Mean Reward: -28.2236000000011. Std of Reward: 27.765820722968535.\n",
      "Step: 2800000. Mean Reward: -80.3075500000002. Std of Reward: 0.5024499999999676.\n",
      "Saved Model\n",
      "Step: 2810000. Mean Reward: -21.942883333333953. Std of Reward: 33.10338431643288.\n",
      "Step: 2820000. Mean Reward: -24.3516000000014. Std of Reward: 42.98330670766506.\n",
      "Step: 2830000. Mean Reward: -43.79975000000014. Std of Reward: 65.03036395422673.\n",
      "Step: 2840000. Mean Reward: -36.67976666666677. Std of Reward: 45.91276380102703.\n",
      "Step: 2850000. Mean Reward: -23.98685000000006. Std of Reward: 26.1681932948348.\n",
      "Saved Model\n",
      "Step: 2860000. Mean Reward: -21.134966666667275. Std of Reward: 37.23328615740148.\n",
      "Step: 2870000. Mean Reward: -34.83188571428583. Std of Reward: 45.90443162233694.\n",
      "Step: 2880000. Mean Reward: -454.5138249999906. Std of Reward: 751.3958668344019.\n",
      "Step: 2890000. Mean Reward: -64.47116666666699. Std of Reward: 69.85595127166293.\n",
      "Step: 2900000. Mean Reward: -46.33157500000062. Std of Reward: 35.04706765011677.\n",
      "Saved Model\n",
      "Step: 2910000. Mean Reward: -62.37227500000104. Std of Reward: 69.58237358848187.\n",
      "Step: 2920000. Mean Reward: -11.144350000000045. Std of Reward: 18.494650000000043.\n",
      "Step: 2930000. Mean Reward: -2892.805066666968. Std of Reward: 4035.36048959898.\n",
      "Step: 2940000. Mean Reward: -52.646300000000124. Std of Reward: 34.53774037911291.\n",
      "Step: 2950000. Mean Reward: -50.80300000000028. Std of Reward: 58.73239405237437.\n",
      "Saved Model\n",
      "Step: 2960000. Mean Reward: -11.688214285714352. Std of Reward: 43.98835766532627.\n",
      "Step: 2970000. Mean Reward: -76.20209999999946. Std of Reward: 123.58103790726291.\n",
      "Step: 2980000. Mean Reward: -115.1356000000003. Std of Reward: 88.04215058644738.\n",
      "Step: 2990000. Mean Reward: -43.6615200000001. Std of Reward: 12.301618419443885.\n",
      "Step: 3000000. Mean Reward: -43.180862500000565. Std of Reward: 69.09628404516363.\n",
      "Saved Model\n",
      "Step: 3010000. Mean Reward: -58.03636000000089. Std of Reward: 89.02458291554463.\n",
      "Step: 3020000. Mean Reward: -2553.6150000002854. Std of Reward: 2563.812600000286.\n",
      "Step: 3030000. Mean Reward: 6.60572500000001. Std of Reward: 4.05981656689992.\n",
      "Step: 3040000. Mean Reward: -27.438120000000094. Std of Reward: 43.56201747354696.\n",
      "Step: 3050000. Mean Reward: -155.31328333333386. Std of Reward: 94.36736774392892.\n",
      "Saved Model\n",
      "Step: 3060000. Mean Reward: -11.386842857142899. Std of Reward: 30.967616084403787.\n",
      "Step: 3070000. Mean Reward: -56.63850000000028. Std of Reward: 75.24160981487171.\n",
      "Step: 3080000. Mean Reward: -6.992700000000018. Std of Reward: 13.23392243164009.\n",
      "Step: 3090000. Mean Reward: -13490.079899997478. Std of Reward: 0.0.\n",
      "Step: 3100000. Mean Reward: -58.80386666666691. Std of Reward: 46.966925862805255.\n",
      "Saved Model\n",
      "Step: 3110000. Mean Reward: 1.4398249999999986. Std of Reward: 9.61541686807573.\n",
      "Step: 3120000. Mean Reward: -23.67518571428626. Std of Reward: 69.1514834728489.\n",
      "Step: 3130000. Mean Reward: -63.139200000000834. Std of Reward: 81.81182702533543.\n",
      "Step: 3140000. Mean Reward: -34.40048571428593. Std of Reward: 73.67046282321704.\n",
      "Step: 3150000. Mean Reward: -17.136566666666855. Std of Reward: 53.3979804292472.\n",
      "Saved Model\n",
      "Step: 3160000. Mean Reward: -45.304133333333674. Std of Reward: 55.463983124777485.\n",
      "Step: 3170000. Mean Reward: -442.282324999991. Std of Reward: 756.7578241525825.\n",
      "Step: 3180000. Mean Reward: -40.64486666666851. Std of Reward: 46.580529575161016.\n",
      "Step: 3190000. Mean Reward: -96.13796666666657. Std of Reward: 123.19795792031425.\n",
      "Step: 3200000. Mean Reward: -31.375120000000162. Std of Reward: 74.81699975846166.\n",
      "Saved Model\n",
      "Step: 3210000. Mean Reward: -79.03318333333351. Std of Reward: 101.1475033507241.\n",
      "Step: 3220000. Mean Reward: -32.640066666666854. Std of Reward: 75.45904253924076.\n",
      "Step: 3230000. Mean Reward: -10.134033333333383. Std of Reward: 29.33715458888654.\n",
      "Step: 3240000. Mean Reward: -3.221299999999895. Std of Reward: 11.646699798941503.\n",
      "Step: 3250000. Mean Reward: -87.94635000000511. Std of Reward: 43.151850000005076.\n",
      "Saved Model\n",
      "Step: 3260000. Mean Reward: -154.57813333333172. Std of Reward: 194.60577049831105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3270000. Mean Reward: -15.383000000000042. Std of Reward: 31.76000516616781.\n",
      "Step: 3280000. Mean Reward: -56.47065000000148. Std of Reward: 54.01474543925529.\n",
      "Step: 3290000. Mean Reward: -108.95110000000285. Std of Reward: 6.135800000002547.\n",
      "Step: 3300000. Mean Reward: 2.6114500000000014. Std of Reward: 8.319429946967544.\n",
      "Saved Model\n",
      "Step: 3310000. Mean Reward: -68.67907500000256. Std of Reward: 16.238278756287475.\n",
      "Step: 3320000. Mean Reward: -26.23320000000106. Std of Reward: 27.21405207327049.\n",
      "Step: 3330000. Mean Reward: -32.36075000000023. Std of Reward: 67.36006219246354.\n",
      "Step: 3340000. Mean Reward: -37.636540000000124. Std of Reward: 49.359710212342335.\n",
      "Step: 3350000. Mean Reward: -77.8555000000021. Std of Reward: 59.03954395606463.\n",
      "Saved Model\n",
      "Step: 3360000. Mean Reward: -18.637400000000028. Std of Reward: 27.983694493847693.\n",
      "Step: 3370000. Mean Reward: -18.63505000000002. Std of Reward: 29.20883237828074.\n",
      "Step: 3380000. Mean Reward: -3399.258800000455. Std of Reward: 3409.4605000004544.\n",
      "Step: 3390000. Mean Reward: -14.6353. Std of Reward: 30.38067261738952.\n",
      "Step: 3400000. Mean Reward: -14.128050000000034. Std of Reward: 40.16345068905939.\n",
      "Saved Model\n",
      "Step: 3410000. Mean Reward: -3425.6885500004555. Std of Reward: 3435.8987500004555.\n",
      "Step: 3420000. Mean Reward: -0.13742499999998872. Std of Reward: 12.656953601750903.\n",
      "Step: 3430000. Mean Reward: -5.625750000000023. Std of Reward: 9.64490549163134.\n",
      "Step: 3440000. Mean Reward: -3431.1939000004554. Std of Reward: 3428.4026000004555.\n",
      "Step: 3450000. Mean Reward: -597.6127666666546. Std of Reward: 823.071217672076.\n",
      "Saved Model\n",
      "Step: 3460000. Mean Reward: -26.458866666666655. Std of Reward: 28.018303278670473.\n",
      "Step: 3470000. Mean Reward: -21.769179999999995. Std of Reward: 22.667997459096377.\n",
      "Step: 3480000. Mean Reward: -8509.846600000956. Std of Reward: 0.0.\n",
      "Step: 3490000. Mean Reward: 4.540566666666675. Std of Reward: 6.655465671828589.\n",
      "Step: 3500000. Mean Reward: -5.567619999999998. Std of Reward: 21.568432816818195.\n",
      "Saved Model\n",
      "Step: 3510000. Mean Reward: -601.8808333333213. Std of Reward: 815.3527622252027.\n",
      "Step: 3530000. Mean Reward: -5961.945249999291. Std of Reward: 5972.154649999291.\n",
      "Step: 3540000. Mean Reward: -2550.749550000282. Std of Reward: 2560.951050000282.\n",
      "Step: 3550000. Mean Reward: -4.291999999999989. Std of Reward: 14.501600000000009.\n",
      "Saved Model\n",
      "Step: 3560000. Mean Reward: -5101.625700000563. Std of Reward: 0.0.\n",
      "Step: 3570000. Mean Reward: -11951.29989999857. Std of Reward: 0.0.\n",
      "Step: 3580000. Mean Reward: -23.459133333333323. Std of Reward: 23.81249973750948.\n",
      "Step: 3590000. Mean Reward: -3.5298666666666634. Std of Reward: 12.810427700987292.\n",
      "Step: 3600000. Mean Reward: -11938.01229999858. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 3610000. Mean Reward: 3.87413333333334. Std of Reward: 8.95701590833814.\n",
      "Step: 3620000. Mean Reward: -66.98595000000037. Std of Reward: 66.84305000000037.\n",
      "Step: 3630000. Mean Reward: -13497.069899997481. Std of Reward: 0.0.\n",
      "Step: 3640000. Mean Reward: -178.43084999999758. Std of Reward: 94.52884999999446.\n",
      "Step: 3650000. Mean Reward: -23.520166666666707. Std of Reward: 19.60528093045909.\n",
      "Saved Model\n",
      "Step: 3660000. Mean Reward: -33.386725000000105. Std of Reward: 21.075035027892064.\n",
      "Step: 3670000. Mean Reward: -9.876950000000035. Std of Reward: 12.091936453790208.\n",
      "Step: 3680000. Mean Reward: -3393.179000000447. Std of Reward: 3356.382700000447.\n",
      "Step: 3690000. Mean Reward: 1.3641999999999956. Std of Reward: 10.247308992364808.\n",
      "Step: 3700000. Mean Reward: -2.626260000000008. Std of Reward: 25.50555039238324.\n",
      "Saved Model\n",
      "Step: 3710000. Mean Reward: -5149.528100000572. Std of Reward: 0.0.\n",
      "Step: 3720000. Mean Reward: -11916.119899998595. Std of Reward: 0.0.\n",
      "Step: 3730000. Mean Reward: -10.792866666666663. Std of Reward: 27.59150769860581.\n",
      "Step: 3740000. Mean Reward: -7.862099999999991. Std of Reward: 18.83689159548357.\n",
      "Step: 3750000. Mean Reward: -11937.11439999858. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 3760000. Mean Reward: -24.795566666666673. Std of Reward: 33.41765528143605.\n",
      "Step: 3770000. Mean Reward: 4.523600000000011. Std of Reward: 4.691300000000009.\n",
      "Step: 3780000. Mean Reward: -13627.209899997408. Std of Reward: 0.0.\n",
      "Step: 3790000. Mean Reward: 7.207066666666688. Std of Reward: 2.8284742758046932.\n",
      "Step: 3800000. Mean Reward: -14.567920000000012. Std of Reward: 21.927371384404484.\n",
      "Saved Model\n",
      "Step: 3810000. Mean Reward: -357.5140599999929. Std of Reward: 689.1000683457627.\n",
      "Step: 3820000. Mean Reward: -30.79659999999992. Std of Reward: 0.0.\n",
      "Step: 3830000. Mean Reward: -4266.412900000467. Std of Reward: 4276.620300000466.\n",
      "Step: 3840000. Mean Reward: -36.38672500000001. Std of Reward: 33.314002979706295.\n",
      "Step: 3850000. Mean Reward: 9.706933333333337. Std of Reward: 0.9427383388594919.\n",
      "Saved Model\n",
      "Step: 3860000. Mean Reward: -4278.743850000474. Std of Reward: 4243.9465500004735.\n",
      "Step: 3870000. Mean Reward: -4.385549999999986. Std of Reward: 18.54845029503813.\n",
      "Step: 3880000. Mean Reward: 1.7059500000000003. Std of Reward: 11.266155082628385.\n",
      "Step: 3890000. Mean Reward: -6.251171428571424. Std of Reward: 17.88654652866339.\n",
      "Step: 3900000. Mean Reward: -855.2564500000573. Std of Reward: 1480.325998050396.\n",
      "Saved Model\n",
      "Step: 3910000. Mean Reward: 10.206800000000019. Std of Reward: 8.164965809330751e-05.\n",
      "Step: 3920000. Mean Reward: 7.829140000000004. Std of Reward: 4.019571741666022.\n",
      "Step: 3930000. Mean Reward: -540.1349999999892. Std of Reward: 734.5643922120948.\n",
      "Step: 3940000. Mean Reward: -27.131033333333345. Std of Reward: 29.829197722403205.\n",
      "Step: 3950000. Mean Reward: -40.17078000000013. Std of Reward: 57.813439664887774.\n",
      "Saved Model\n",
      "Step: 3960000. Mean Reward: -22.886339999999947. Std of Reward: 28.2545640111894.\n",
      "Step: 3970000. Mean Reward: 6.206600000000021. Std of Reward: 4.0009999999999994.\n",
      "Step: 3980000. Mean Reward: -2578.1855000002834. Std of Reward: 2543.3874000002834.\n",
      "Step: 3990000. Mean Reward: -41.13535000000033. Std of Reward: 46.53146722410039.\n",
      "Step: 4000000. Mean Reward: -20.960966666666696. Std of Reward: 32.487762295499685.\n",
      "Saved Model\n",
      "Step: 4010000. Mean Reward: -1706.0163500001147. Std of Reward: 1715.2171500001148.\n",
      "Step: 4020000. Mean Reward: -8517.92060000095. Std of Reward: 0.0.\n",
      "Step: 4030000. Mean Reward: 10.206533333333352. Std of Reward: 0.000309120616515803.\n",
      "Step: 4040000. Mean Reward: -6.3679200000000105. Std of Reward: 16.82324738085963.\n",
      "Step: 4050000. Mean Reward: -8520.80910000095. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 4070000. Mean Reward: -5990.5161999993. Std of Reward: 5918.7136999993.\n",
      "Step: 4080000. Mean Reward: -1.634249999999971. Std of Reward: 15.132883406426526.\n",
      "Step: 4090000. Mean Reward: -30.128983333333462. Std of Reward: 51.34802904595991.\n",
      "Step: 4100000. Mean Reward: -2.6535166666666723. Std of Reward: 17.238751991121323.\n",
      "Saved Model\n",
      "Step: 4110000. Mean Reward: -18.645533333333322. Std of Reward: 12.646664871902864.\n",
      "Step: 4120000. Mean Reward: 10.372750000000002. Std of Reward: 0.0006500000000002615.\n",
      "Step: 4130000. Mean Reward: -5103.389949999886. Std of Reward: 5113.595249999886.\n",
      "Step: 4140000. Mean Reward: -8491.735100000968. Std of Reward: 0.0.\n",
      "Step: 4150000. Mean Reward: -26.128266666666644. Std of Reward: 29.80966027116417.\n",
      "Saved Model\n",
      "Step: 4160000. Mean Reward: -14.367200000000002. Std of Reward: 17.654223443584257.\n",
      "Step: 4170000. Mean Reward: -8508.758300000956. Std of Reward: 0.0.\n",
      "Step: 4180000. Mean Reward: 8.206200000000019. Std of Reward: 2.829699927554156.\n",
      "Step: 4190000. Mean Reward: -6.979050000000034. Std of Reward: 6.816650000000036.\n",
      "Step: 4200000. Mean Reward: -13578.029899997442. Std of Reward: 0.0.\n",
      "Saved Model\n",
      "Step: 4210000. Mean Reward: 9.87280000000002. Std of Reward: 0.47093382408430395.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "if curriculum_file == \"None\":\n",
    "    curriculum_file = None\n",
    "\n",
    "\n",
    "def get_progress():\n",
    "    if curriculum_file is not None:\n",
    "        if env._curriculum.measure_type == \"progress\":\n",
    "            return steps / max_steps\n",
    "        elif env._curriculum.measure_type == \"reward\":\n",
    "            return last_reward\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create the Tensorflow model graph\n",
    "ppo_model = create_agent_model(env, lr=learning_rate,\n",
    "                               h_size=hidden_units, epsilon=epsilon,\n",
    "                               beta=beta, max_step=max_steps, \n",
    "                               normalize=normalize, num_layers=num_layers)\n",
    "\n",
    "is_continuous = (env.brains[brain_name].action_space_type == \"continuous\")\n",
    "use_observations = (env.brains[brain_name].number_observations > 0)\n",
    "use_states = (env.brains[brain_name].state_space_size > 0)\n",
    "\n",
    "model_path = './models/{}'.format(run_path)\n",
    "summary_path = './summaries/{}'.format(run_path)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    # Instantiate model parameters\n",
    "    if load_model:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    steps, last_reward = sess.run([ppo_model.global_step, ppo_model.last_reward])    \n",
    "    summary_writer = tf.summary.FileWriter(summary_path)\n",
    "    info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "    trainer = Trainer(ppo_model, sess, info, is_continuous, use_observations, use_states, train_model)\n",
    "    if train_model:\n",
    "        trainer.write_text(summary_writer, 'Hyperparameters', hyperparameter_dict, steps)\n",
    "    while steps <= max_steps:\n",
    "        if env.global_done:\n",
    "            info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "        # Decide and take an action\n",
    "        new_info = trainer.take_action(info, env, brain_name, steps, normalize)\n",
    "        info = new_info\n",
    "        trainer.process_experiences(info, time_horizon, gamma, lambd)\n",
    "        if len(trainer.training_buffer['actions']) > buffer_size and train_model:\n",
    "            # Perform gradient descent with experience buffer\n",
    "            trainer.update_model(batch_size, num_epoch)\n",
    "        if steps % summary_freq == 0 and steps != 0 and train_model:\n",
    "            # Write training statistics to tensorboard.\n",
    "            trainer.write_summary(summary_writer, steps, env._curriculum.lesson_number)\n",
    "        if steps % save_freq == 0 and steps != 0 and train_model:\n",
    "            # Save Tensorflow model\n",
    "            save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "        steps += 1\n",
    "        sess.run(ppo_model.increment_step)\n",
    "        if len(trainer.stats['cumulative_reward']) > 0:\n",
    "            mean_reward = np.mean(trainer.stats['cumulative_reward'])\n",
    "            sess.run(ppo_model.update_reward, feed_dict={ppo_model.new_reward: mean_reward})\n",
    "            last_reward = sess.run(ppo_model.last_reward)\n",
    "    # Final save Tensorflow model\n",
    "    if steps != 0 and train_model:\n",
    "        save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "env.close()\n",
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the trained Tensorflow graph\n",
    "Once the model has been trained and saved, we can export it as a .bytes file which Unity can embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
